{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Assistants API - Function Calling**\n",
    "\n",
    "An assistant is a purpose-built AI that has specific instructions, leverages extra knowledge, and can call models and tools to perform tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://platform.openai.com/docs/assistants/how-it-works/objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "from openai import OpenAI\n",
    "import json\n",
    "\n",
    "_ = load_dotenv(find_dotenv())\n",
    "client: OpenAI = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Function Calling**\n",
    "\n",
    "Similar to the Chat Completions API, the Assistants API supports function calling. Function calling allows you to describe functions to the Assistants and have it intelligently return the functions that need to be called along with their arguments. The Assistants API will pause execution during a Run when it invokes functions, and you can supply the results of the function call back to continue the Run execution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 0: Define Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example dummy function hard coded to return the same weather\n",
    "# In production, this could be your backend API or an external API\n",
    "def getCurrentWeather(location: str, unit:str=\"fahrenheit\") -> str | dict | None: \n",
    "    if \"tokyo\" in location.lower():\n",
    "        return json.dumps({\"location\": \"Tokyo\", \"temperature\": \"10\", \"unit\": \"celsius\"})\n",
    "    elif \"los angeles\" in location.lower():\n",
    "        return json.dumps({\"location\": \"San Francisco\", \"temperature\": \"72\", \"unit\": \"fahrenheit\"})\n",
    "    elif \"paris\" in location.lower():\n",
    "        return json.dumps({\"location\": \"Paris\", \"temperature\": \"22\", \"unit\": \"celsius\"})\n",
    "    else:\n",
    "        return json.dumps({\"location\": location, \"temperature\": \"unknown\"})\n",
    "    \n",
    "def getNickname(location:str)->str:\n",
    "    \"\"\"Get the nickname of a city\"\"\"\n",
    "    if \"tokyo\" in location.lower():\n",
    "        return \"tk\"\n",
    "    elif \"los angeles\" in location.lower():\n",
    "        return \"la\"\n",
    "    elif \"paris\" in location.lower():\n",
    "        return \"py\"\n",
    "    else:\n",
    "        return location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 1: Create an Assistant and register/report your functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def show_json(message, obj):\n",
    "    display(message, json.loads(obj.model_dump_json())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai.types.beta.assistant import Assistant\n",
    "\n",
    "assistant: Assistant = client.beta.assistants.create(\n",
    "    instructions=\"You are a weather bot. Use the provided functions to answer questions.\",\n",
    "    model=\"gpt-3.5-turbo-1106\",\n",
    "    tools=[\n",
    "        {\n",
    "            \"type\":\"function\",\n",
    "            \"function\": {\n",
    "                \"name\":\"getCurrentWeather\",\n",
    "                \"description\": \"Get the weather in location\",\n",
    "                \"parameters\":{\n",
    "                    \"type\":\"object\",\n",
    "                    \"properties\":{\n",
    "                        \"location\":{\"type\":\"string\", \"description\": \"The city and state e.g. San Francisco, CA\"},\n",
    "                        \"unit\":{\"type\":\"string\", \"enum\": [\"c\", \"f\"]},\n",
    "                    },\n",
    "                    \"required\": [\"location\"]\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "            \"name\": \"getNickname\",\n",
    "            \"description\": \"Get the nickname of a city\",\n",
    "            \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                    \"location\": {\"type\": \"string\", \"description\": \"The city and state e.g. San Francisco, CA\"},\n",
    "                    },\n",
    "                    \"required\": [\"location\"]\n",
    "                }\n",
    "            } \n",
    "        }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 2: Create a Thread**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread(id='thread_GtNtop1eWQugTnwrSHIm8ngl', created_at=1704311620, metadata={}, object='thread')\n"
     ]
    }
   ],
   "source": [
    "from openai.types.beta.thread import Thread\n",
    "\n",
    "thread: Thread = client.beta.threads.create()\n",
    "\n",
    "print(thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai.types.beta.threads.thread_message import ThreadMessage\n",
    "\n",
    "message: ThreadMessage = client.beta.threads.messages.create(\n",
    "    content=\"How is the weather in Los Angles?\",\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'msg_OKdWlTXadBVxwzLcs9MrkbUw',\n",
       " 'assistant_id': None,\n",
       " 'content': [MessageContentText(text=Text(annotations=[], value='How is the weather in Los Angles?'), type='text')],\n",
       " 'created_at': 1704311620,\n",
       " 'file_ids': [],\n",
       " 'metadata': {},\n",
       " 'object': 'thread.message',\n",
       " 'role': 'user',\n",
       " 'run_id': None,\n",
       " 'thread_id': 'thread_GtNtop1eWQugTnwrSHIm8ngl'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 4: Run the Assistant**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai.types.beta.threads.run import Run\n",
    "\n",
    "run: Run = client.beta.threads.runs.create(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=assistant.id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'run_24QXLWPu2DLu6xo2l9gGW1sv',\n",
       " 'assistant_id': 'asst_LtB3aQiQcthXGkKdruePlFxY',\n",
       " 'cancelled_at': None,\n",
       " 'completed_at': None,\n",
       " 'created_at': 1704311621,\n",
       " 'expires_at': 1704312221,\n",
       " 'failed_at': None,\n",
       " 'file_ids': [],\n",
       " 'instructions': 'You are a weather bot. Use the provided functions to answer questions.',\n",
       " 'last_error': None,\n",
       " 'metadata': {},\n",
       " 'model': 'gpt-3.5-turbo-1106',\n",
       " 'object': 'thread.run',\n",
       " 'required_action': None,\n",
       " 'started_at': None,\n",
       " 'status': 'queued',\n",
       " 'thread_id': 'thread_GtNtop1eWQugTnwrSHIm8ngl',\n",
       " 'tools': [ToolAssistantToolsFunction(function=FunctionDefinition(name='getCurrentWeather', parameters={'type': 'object', 'properties': {'location': {'type': 'string', 'description': 'The city and state e.g. San Francisco, CA'}, 'unit': {'type': 'string', 'enum': ['c', 'f']}}, 'required': ['location']}, description='Get the weather in location'), type='function'),\n",
       "  ToolAssistantToolsFunction(function=FunctionDefinition(name='getNickname', parameters={'type': 'object', 'properties': {'location': {'type': 'string', 'description': 'The city and state e.g. San Francisco, CA'}}, 'required': ['location']}, description='Get the nickname of a city'), type='function')]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Run Life Cycle**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt Text](diagram.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_functions = {\n",
    "    \"getCurrentWeather\": getCurrentWeather,\n",
    "    \"getNickname\": getNickname,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'thread_GtNtop1eWQugTnwrSHIm8ngl'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thread.id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 5: Polling for Updates and Calling Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in_progress .....\n",
      "Run is queued. Waiting...\n",
      "requires_action .....\n",
      "requires_action .....\n",
      "Status:  requires_action\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'submit_tool_outputs'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'submit_tool_outputs': {'tool_calls': [{'id': 'call_nGai6nE8DGAivXVR8AHk097R',\n",
       "    'function': {'arguments': '{\"location\":\"Los Angeles, CA\",\"unit\":\"c\"}',\n",
       "     'name': 'getCurrentWeather'},\n",
       "    'type': 'function'}]},\n",
       " 'type': 'submit_tool_outputs'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toolCalls present:\n",
      "<function getCurrentWeather at 0x109e59c60> True ================================================================\n",
      "[{'tool_call_id': 'call_nGai6nE8DGAivXVR8AHk097R', 'output': '{\"location\": \"San Francisco\", \"temperature\": \"72\", \"unit\": \"fahrenheit\"}'}] >>>>>\n",
      "in_progress .....\n",
      "Run is queued. Waiting...\n",
      "completed .....\n",
      "completed...........logic\n",
      "Assistant: The current temperature in Los Angeles, CA is 72°F.\n",
      "\n",
      "User: How is the weather in Los Angles?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "  # Loop until the run completes or requires action\n",
    "while True:\n",
    "    runStatus = client.beta.threads.runs.retrieve(thread_id=thread.id,\n",
    "                                                  run_id=run.id)\n",
    "    # Add run steps retrieval here for debuging\n",
    "    run_steps = client.beta.threads.runs.steps.list(thread_id=thread.id, run_id=run.id)\n",
    "    # show_json(\"Run Steps:\", run_steps)\n",
    "    print(runStatus.status ,'.....')\n",
    "\n",
    "    # This means run is making a function call   \n",
    "    if runStatus.status == \"requires_action\":\n",
    "        print(runStatus.status ,'.....')\n",
    "        print(\"Status: \", \"requires_action\")\n",
    "        show_json(\"submit_tool_outputs\", runStatus.required_action)\n",
    "        if runStatus.required_action.submit_tool_outputs and runStatus.required_action.submit_tool_outputs.tool_calls:\n",
    "            print(\"toolCalls present:\")\n",
    "            toolCalls = runStatus.required_action.submit_tool_outputs.tool_calls\n",
    "\n",
    "            tool_outputs = []\n",
    "            for toolcall in toolCalls:\n",
    "                function_name = toolcall.function.name\n",
    "                function_args = json.loads(toolcall.function.arguments)\n",
    "                \n",
    "                if function_name in available_functions:\n",
    "                    \n",
    "                    \n",
    "                    function_to_call = available_functions[function_name]\n",
    "                    print(function_to_call,function_to_call.__name__==\"getCurrentWeather\",\"================================================================\")\n",
    "                  \n",
    "                    if function_to_call.__name__ == \"getCurrentWeather\":\n",
    "                        \n",
    "                        response = function_to_call(\n",
    "                        location=function_args.get(\"location\"),\n",
    "                        unit=function_args.get(\"unit\")\n",
    "                        )\n",
    "                        \n",
    "                        \n",
    "                        tool_outputs.append({\n",
    "                                  \"tool_call_id\": toolcall.id,\n",
    "                                  \"output\": response\n",
    "                              })\n",
    "                    \n",
    "                    elif function_to_call.__name__ == \"getNickname\":\n",
    "                        response = function_to_call(\n",
    "                          location=function_args.get(\"location\")\n",
    "                          )\n",
    "                        tool_outputs.append({\n",
    "                          \"tool_call_id\": toolcall.id,\n",
    "                          \"output\": response,\n",
    "                              })\n",
    "            print(tool_outputs,\">>>>>\") \n",
    "            # Submit tool outputs and update the run\n",
    "            client.beta.threads.runs.submit_tool_outputs(\n",
    "                thread_id=thread.id,\n",
    "                run_id=run.id,\n",
    "                tool_outputs=tool_outputs)\n",
    "      \n",
    "    elif runStatus.status == \"completed\":\n",
    "        # List the messages to get the response\n",
    "        print(\"completed...........logic\")\n",
    "        messages: list[ThreadMessage] = client.beta.threads.messages.list(thread_id=thread.id)\n",
    "        for message in messages.data:\n",
    "            role_label = \"User\" if message.role == \"user\" else \"Assistant\"\n",
    "            message_content = message.content[0].text.value\n",
    "            print(f\"{role_label}: {message_content}\\n\")\n",
    "        break  # Exit the loop after processing the completed run\n",
    "\n",
    "    elif run.status == \"failed\":\n",
    "      print(\"Run failed.\")\n",
    "      break\n",
    "\n",
    "    elif run.status in [\"in_progress\", \"queued\"]:\n",
    "      print(f\"Run is {run.status}. Waiting...\")\n",
    "      time.sleep(5)  # Wait for 5 seconds before checking again\n",
    "\n",
    "    else:\n",
    "      print(f\"Unexpected status: {run.status}\")\n",
    "      break\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shahzaibse-langchain-v1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
