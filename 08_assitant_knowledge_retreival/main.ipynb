{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Knowledge Retreival**\n",
    "\n",
    "Retrieval augments the Assistant with knowledge from outside its model, such as proprietary product information or documents provided by your users. Once a file is uploaded and passed to the Assistant, OpenAI will automatically chunk your documents, index and store the embeddings, and implement vector search to retrieve relevant content to answer user queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_ : bool = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "client: OpenAI = OpenAI()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 1: Upload a File and Create an Assistant**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai.types.beta import Assistant\n",
    "\n",
    "# Without \"rb\" TypeError: Multipart file uploads must be opened in binary mode, not text mode.\n",
    "file: Assistant = client.files.create(\n",
    "    file=open(\"./zia_profile.pdf\", \"rb\"),\n",
    "    purpose=\"assistants\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt Text](objects.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt Text](ret.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with the Assistant API using Retrieval tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "myAssistant: Assistant = client.beta.assistants.create(\n",
    "    name=\"Student Support Assistant\",\n",
    "    instructions=\"You are a student support chatbot. Use your knowledge base to best respond to student queries about Zia U. Khan.\",\n",
    "    tools=[{\"type\":\"retrieval\"}],\n",
    "    model=\"gpt-3.5-turbo-1106\",\n",
    "    file_ids=[file.id]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 2: Create a Thread**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread(id='thread_UxhHk6CIC4fpsrjf5N8h0ypC', created_at=1703360268, metadata={}, object='thread')\n"
     ]
    }
   ],
   "source": [
    "from openai.types.beta.thread import Thread\n",
    "\n",
    "thread: Thread = client.beta.threads.create()\n",
    "\n",
    "print(thread)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 3: Add a Thread Message**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai.types.beta.threads.thread_message import ThreadMessage\n",
    "\n",
    "message: ThreadMessage = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=\"When and which city Zia U. Khan was born?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 4: Run Assistant**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run(id='run_W0iYNpB9WqWNHMgRr9vO1DoB', assistant_id='asst_OjW1zxl8MkH5S5mjBIoRhm9r', cancelled_at=None, completed_at=None, created_at=1703360875, expires_at=1703361475, failed_at=None, file_ids=['file-ycRrCR8AHkbwq8K95AnCX40U'], instructions='When and which city Zia U. Khan was born?', last_error=None, metadata={}, model='gpt-3.5-turbo-1106', object='thread.run', required_action=None, started_at=None, status='queued', thread_id='thread_UxhHk6CIC4fpsrjf5N8h0ypC', tools=[ToolAssistantToolsRetrieval(type='retrieval')])\n"
     ]
    }
   ],
   "source": [
    "from openai.types.beta.threads.run import Run\n",
    "\n",
    "run: Run = client.beta.threads.runs.create(\n",
    "    assistant_id=myAssistant.id,\n",
    "    thread_id=thread.id,\n",
    "    instructions=\"When and which city Zia U. Khan was born?\"\n",
    ")\n",
    "print(run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 5: Check Run Status**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run(id='run_W0iYNpB9WqWNHMgRr9vO1DoB', assistant_id='asst_OjW1zxl8MkH5S5mjBIoRhm9r', cancelled_at=None, completed_at=1703360877, created_at=1703360875, expires_at=None, failed_at=None, file_ids=['file-ycRrCR8AHkbwq8K95AnCX40U'], instructions='When and which city Zia U. Khan was born?', last_error=None, metadata={}, model='gpt-3.5-turbo-1106', object='thread.run', required_action=None, started_at=1703360876, status='completed', thread_id='thread_UxhHk6CIC4fpsrjf5N8h0ypC', tools=[ToolAssistantToolsRetrieval(type='retrieval')])\n"
     ]
    }
   ],
   "source": [
    "run: Run = client.beta.threads.runs.retrieve(\n",
    "    thread_id=thread.id,\n",
    "    run_id=run.id\n",
    ")\n",
    "\n",
    "print(run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 6: Assistant Response**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: When and which city Zia U. Khan was born?\n",
      "assistant: Zia U. Khan was born in Sialkot, Pakistan in 1961【7†source】.\n",
      "assistant: Zia U. Khan was born in Sialkot in 1961【6†source】.\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "messages: List = client.beta.threads.messages.list(\n",
    "    thread_id=thread.id\n",
    ")\n",
    "\n",
    "for message in reversed(messages.data):\n",
    "    print(message.role + \": \" + message.content[0].text.value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shahzaibse-langchain-v1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
